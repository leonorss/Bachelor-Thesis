Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	SingleCellReadSimulator
	1	createGermlineMutations
	1	createMutations
	1	generateBinaryTree
	8	indexMutations
	8	insertMutations
	1	plotBinaryTree
	8	simulateReads
	8	sortMutations
	8	zipMutations
	45

[Fri Jun 14 15:25:17 2019]
rule createGermlineMutations:
    output: Data/Mutations/GermlineMutationsTest_Allel1.vcf, Data/Mutations/GermlineMutationsTest_Allel2.vcf
    jobid: 44
    benchmark: benchmarks/benchmarkGermlineMutations_Test.txt
    wildcards: treename=Test

[Fri Jun 14 15:25:17 2019]
Error in rule createGermlineMutations:
    jobid: 44
    output: Data/Mutations/GermlineMutationsTest_Allel1.vcf, Data/Mutations/GermlineMutationsTest_Allel2.vcf
    conda-env: /Users/leonorschubert/Desktop/Aramis/ETH/Bachelor Thesis/Code/.snakemake/conda/3f895cc5

WorkflowError:
Python 3 package psutil needs to be installed to use the benchmarking.
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/thread.py", line 57, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/leonorschubert/Desktop/Aramis/ETH/Bachelor Thesis/Code/.snakemake/log/2019-06-14T152517.295941.snakemake.log
